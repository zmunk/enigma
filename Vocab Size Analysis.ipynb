{"cells":[{"cell_type":"code","source":["## UTILITIES\n\nimport re\n\ndef check_distinct(rdd):\n  ''' check if all words in dict_ are distinct '''\n  tweet_ids = rdd.map(lambda x: x[0])\n  total_count = tweet_ids.count()\n  distinct_count = tweet_ids.distinct().count()\n  if total_count == distinct_count:\n    print(\"All tweets are distinct\")\n  else:\n    print(\"All tweets are NOT distinct\")\n  \n  \ndef process(text):\n  ''' remove punctuation, make all lowercase, split'''\n  pattern = re.compile('[^\\w ]+')\n  text = pattern.sub('', text) # remove punctuation\n  text = text.lower() # make lowercase\n  return text.split(\" \")\n\n  \ndef binary_search(val, arr):\n  ''' binary search for val in arr\n  return index if exists, otherwise -1\n  '''\n  left, right = 0, len(arr) - 1\n  while left <= right:\n      mid = left + (right - left) // 2\n      mid_val = arr[mid]\n      if val < mid_val:\n          right = mid - 1\n      elif val > mid_val:\n          left = mid + 1\n      else:\n          return mid\n  return -1\n\n\ndef clean_word(word):\n  ''' remove non-alphanumeric and make lowercase '''\n  pattern = re.compile('[\\W]+')\n  return pattern.sub('', word.lower()) \n\n\n# get list of legitimate english words\nENGLISH_WORDS = sorted(sc.textFile(\"/FileStore/tables/words.txt\").map(clean_word).collect())\n\n\ndef is_legit(word):\n  ''' check if word is a legitimate english word '''\n  if binary_search(word[0], ENGLISH_WORDS) >= 0:\n    return True\n  return False"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":1},{"cell_type":"code","source":["def vocab_ratio(username, tweets):\n  ''' Analyzes tweets of user to determine the vocab size per 10k words '''  \n  SAMPLE_SIZE = 5000\n#   username, tweets = user\n  rdd = sc.parallelize(tweets.asDict().items())\n  print(f\"processing tweets of: {username}\")\n#   check_distinct(rdd)\n  # extract only text, and filter out retweets\n  tweets_rdd = rdd.map(lambda x: x[1]).filter(lambda tweet: tweet[:2] != \"RT\")\n  # separate words, filter out improper words\n  words_rdd = tweets_rdd.flatMap(process).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b).filter(is_legit).flatMap(lambda x: [x[0]] * x[1])\n  # randomly sampling 10k words\n  total_count = words_rdd.count()\n  if total_count < SAMPLE_SIZE:\n    print(\"not enough words\")\n    return\n  sampled_rdd = words_rdd.sample(withReplacement=False, fraction=SAMPLE_SIZE/total_count)\n  # count frequency of each word\n  freq_rdd = sampled_rdd.map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n  distinct_count = freq_rdd.count()\n  sampled_count = sampled_rdd.count()\n  ratio = distinct_count / sampled_count\n  print(f\"{distinct_count} out of {sampled_count} words. Ratio: {ratio}\")\n  return ratio\n  "],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":2},{"cell_type":"code","source":["file_location = \"/FileStore/tables/all_tweets.json\"\nrdd = spark.read.option(\"multiline\", \"true\").json(file_location).rdd.flatMap(lambda x: list(x.asDict().items()))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"code","source":["ratio_dict = {}\nfor user in rdd.collect():\n  username, tweets = user\n  ratio = vocab_ratio(username, tweets)\n  ratio_dict[username] = ratio"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">processing tweets of: ArmanRo36332524\n1193 out of 5016 words. Ratio: 0.2378389154704944\nprocessing tweets of: Bala06809628\nnot enough words\nprocessing tweets of: BeIshita\n1550 out of 4998 words. Ratio: 0.31012404961984796\nprocessing tweets of: BeingKalptaru\nnot enough words\nprocessing tweets of: BichAssClaudia\n1229 out of 5000 words. Ratio: 0.2458\nprocessing tweets of: BieberPrasad\nnot enough words\nprocessing tweets of: BottomAmethyst\n1322 out of 4955 words. Ratio: 0.26680121089808273\nprocessing tweets of: BryanDMcNally\n1473 out of 5037 words. Ratio: 0.29243597379392494\nprocessing tweets of: CrownTheGrind\nnot enough words\nprocessing tweets of: DIAMONDRED05\nnot enough words\nprocessing tweets of: Goodweeed_m\n1167 out of 4982 words. Ratio: 0.23424327579285428\nprocessing tweets of: JeffreyLuscombe\n1703 out of 5008 words. Ratio: 0.340055910543131\nprocessing tweets of: Kayla_Patriceee\n1085 out of 4942 words. Ratio: 0.21954674220963172\nprocessing tweets of: KieranK13ran\nnot enough words\nprocessing tweets of: LivingSno\n1674 out of 4899 words. Ratio: 0.3417023882424985\nprocessing tweets of: MeMuddaFuckka\n1145 out of 4944 words. Ratio: 0.23159385113268607\nprocessing tweets of: Memetherapy1\n1656 out of 5019 words. Ratio: 0.3299462044231919\nprocessing tweets of: Mifaunuagbo\n1372 out of 5040 words. Ratio: 0.2722222222222222\nprocessing tweets of: MirandaPokorsk\nnot enough words\nprocessing tweets of: Morecently\nnot enough words\nprocessing tweets of: NWellyf\n1576 out of 5021 words. Ratio: 0.31388169687313283\nprocessing tweets of: NoNeedToBeKnow2\nnot enough words\nprocessing tweets of: OfficialNYCG\nnot enough words\nprocessing tweets of: Orangezipple1\n1415 out of 4947 words. Ratio: 0.2860319385486153\nprocessing tweets of: OtbVontee\n1007 out of 5019 words. Ratio: 0.20063757720661488\nprocessing tweets of: PatriotTrump77\nnot enough words\nprocessing tweets of: PhDholda\n1191 out of 5073 words. Ratio: 0.23477232406859846\nprocessing tweets of: Preeti86266373\nnot enough words\nprocessing tweets of: RJKINGJOHNSON\nnot enough words\nprocessing tweets of: RabinaMagar13\nnot enough words\nprocessing tweets of: Riarna_K\nnot enough words\nprocessing tweets of: RobWils88348869\nnot enough words\nprocessing tweets of: Royal_SeokJin\nnot enough words\nprocessing tweets of: Sam_Vinokor\n1869 out of 5030 words. Ratio: 0.3715705765407555\nprocessing tweets of: Sh3n1gam1\nnot enough words\nprocessing tweets of: Shamiso_\n1261 out of 4961 words. Ratio: 0.2541826244708728\nprocessing tweets of: TPRISl\nnot enough words\nprocessing tweets of: TRUMPGETGO\nnot enough words\nprocessing tweets of: TaskForceStaff\n917 out of 5005 words. Ratio: 0.18321678321678322\nprocessing tweets of: TomasHearty\n1432 out of 5025 words. Ratio: 0.28497512437810946\nprocessing tweets of: TrechxTV\n1137 out of 4941 words. Ratio: 0.23011536126290225\nprocessing tweets of: Vwinterbear_95\nnot enough words\nprocessing tweets of: WarzoneSpace\n1264 out of 5050 words. Ratio: 0.2502970297029703\nprocessing tweets of: Yo_ShiSmooth\n1112 out of 5033 words. Ratio: 0.2209417842241208\nprocessing tweets of: alyaJoooooo\nnot enough words\nprocessing tweets of: anthonylauro_\n1463 out of 5024 words. Ratio: 0.29120222929936307\nprocessing tweets of: bertus161057\nnot enough words\nprocessing tweets of: btssowooju\n1190 out of 5049 words. Ratio: 0.2356902356902357\nprocessing tweets of: chaloxcervantes\n1240 out of 5046 words. Ratio: 0.24573919936583433\nprocessing tweets of: chamomicrossing\nnot enough words\nprocessing tweets of: chan_minsshi\nnot enough words\nprocessing tweets of: chandlerblackEP\nnot enough words\nprocessing tweets of: choconaut_\n1393 out of 4894 words. Ratio: 0.2846342460155292\nprocessing tweets of: colleenmerrells\n1117 out of 5101 words. Ratio: 0.21897667124093315\nprocessing tweets of: connornuts\n1497 out of 4998 words. Ratio: 0.2995198079231693\nprocessing tweets of: conser_usa\n1101 out of 5105 words. Ratio: 0.2156709108716944\nprocessing tweets of: domcrofts\n1504 out of 4880 words. Ratio: 0.3081967213114754\nprocessing tweets of: dumbricardo\n1250 out of 4973 words. Ratio: 0.25135732957973056\nprocessing tweets of: evanasher555\nnot enough words\nprocessing tweets of: floridagal68\nnot enough words\nprocessing tweets of: gadwalmallu\nnot enough words\nprocessing tweets of: gavinmelton59\nnot enough words\nprocessing tweets of: georgemo7\nnot enough words\nprocessing tweets of: hippie_hal\nnot enough words\nprocessing tweets of: idalith_loya19\n1219 out of 4915 words. Ratio: 0.24801627670396745\nprocessing tweets of: imnbalqis\nnot enough words\nprocessing tweets of: indemnitypop\n1677 out of 5056 words. Ratio: 0.3316851265822785\nprocessing tweets of: ir3oluwa\nnot enough words\nprocessing tweets of: jfuller929\nnot enough words\nprocessing tweets of: johnnymup\n1496 out of 4992 words. Ratio: 0.29967948717948717\nprocessing tweets of: juanzaa\nnot enough words\nprocessing tweets of: karla_handley\nnot enough words\nprocessing tweets of: kkrao1108\nnot enough words\nprocessing tweets of: lilalienboi_\n1150 out of 4971 words. Ratio: 0.23134178233755784\nprocessing tweets of: llysandrra\nnot enough words\nprocessing tweets of: loveoffreedom76\nnot enough words\nprocessing tweets of: meshary2811\n1355 out of 5001 words. Ratio: 0.2709458108378324\nprocessing tweets of: mimiraii123\nnot enough words\nprocessing tweets of: mitulsparekh\nnot enough words\nprocessing tweets of: nicholasminken\nnot enough words\nprocessing tweets of: othermaciej\n1565 out of 4851 words. Ratio: 0.3226138940424655\nprocessing tweets of: pimpinserenity\nnot enough words\nprocessing tweets of: pjmstolemyheart\nnot enough words\nprocessing tweets of: praneeta_kuanr\n1185 out of 4993 words. Ratio: 0.23733226517123973\nprocessing tweets of: prashanth_km\nnot enough words\nprocessing tweets of: retrojungs\nnot enough words\nprocessing tweets of: saintLumy\n1257 out of 4948 words. Ratio: 0.2540420371867421\nprocessing tweets of: shadowyoonii\n1072 out of 5030 words. Ratio: 0.21312127236580516\nprocessing tweets of: shebJAMmin\n1356 out of 4990 words. Ratio: 0.2717434869739479\nprocessing tweets of: sudhirmenon21\n1589 out of 4986 words. Ratio: 0.3186923385479342\nprocessing tweets of: supr_me_\nnot enough words\nprocessing tweets of: taexandrion\nnot enough words\nprocessing tweets of: talhajawed_\n1207 out of 5001 words. Ratio: 0.24135172965406917\nprocessing tweets of: thathboy\nnot enough words\nprocessing tweets of: twitbycs\nnot enough words\nprocessing tweets of: ublolni\nnot enough words\nprocessing tweets of: unitambo\n2098 out of 4970 words. Ratio: 0.4221327967806841\nprocessing tweets of: varshini1997\nnot enough words\nprocessing tweets of: workatIHAPIHAP\n1132 out of 4997 words. Ratio: 0.22653592155293176\nprocessing tweets of: yay_tunes\n1297 out of 5145 words. Ratio: 0.252089407191448\nprocessing tweets of: yorkiefights\n1595 out of 5050 words. Ratio: 0.31584158415841584\n</div>"]}}],"execution_count":4},{"cell_type":"code","source":["ratio_dict"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["import json\n\nwrite_file_location = \"/dbfs/FileStore/output/ratio_dict.txt\"\nwith open(write_file_location, 'w') as f:\n  f.write(json.dumps(ratio_dict))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":6},{"cell_type":"code","source":["## reading and writing file\n# file location: \"/dbfs/FileStore/output/test_file.txt\"\n# url to download file: https://community.cloud.databricks.com/files/output/ratio_dict.txt?o=8290779921351936"],"metadata":{},"outputs":[],"execution_count":7}],"metadata":{"name":"Vocab Size Analysis","notebookId":590370730699966},"nbformat":4,"nbformat_minor":0}
